<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <title>Naveen Dharavath | Data Engineer</title>
  <meta name="description" content="Naveen Dharavath ‚Äî Data Engineer specializing in ETL, PySpark, Airflow, AWS, and Snowflake." />
  <link rel="stylesheet" href="style.css" />
</head>
<body>
  <header class="container">
    <div class="hero">
      <div>
        <h1>Naveen Dharavath</h1>
        <p class="subtitle">Data Engineer ‚Ä¢ ETL/ELT ‚Ä¢ PySpark ‚Ä¢ Airflow ‚Ä¢ AWS ‚Ä¢ Snowflake</p>

        <div class="cta">
          <a class="btn" href="mailto:naveendharavath10032000@gmail.com">Email</a>
          <a class="btn btn-ghost" href="https://www.linkedin.com/in/naveen-dharavathde/" target="_blank" rel="noreferrer">LinkedIn</a>
          <a class="btn btn-ghost" href="https://github.com/naveendharavath" target="_blank" rel="noreferrer">GitHub</a>
        </div>

        <ul class="meta">
          <li>üìç USA</li>
          <li>üìû 928-221-8870</li>
          <li>‚úâÔ∏è naveend102000@gmail.com</li>
        </ul>
      </div>

      <div class="card quick">
        <h2>Quick Highlights</h2>
        <ul>
          <li>3+ years building data pipelines & cloud data platforms</li>
          <li>Banking + Healthcare domain experience</li>
          <li>Strong in Python, SQL, PySpark, Airflow, AWS, Snowflake</li>
        </ul>
      </div>
    </div>
  </header>

  <main class="container">
    <section class="card">
      <h2>Professional Summary</h2>
      <p>
        Results-oriented Data Engineer with 3+ years of experience designing, building, and optimizing
        data pipelines, ETL workflows, and cloud-based data infrastructure across banking and healthcare.
        Skilled in Python, SQL, PySpark, Airflow, AWS, and Snowflake, with expertise in data modeling,
        orchestration, and real-time analytics enablement.
      </p>
    </section>

    <section class="grid">
      <section class="card">
        <h2>Skills</h2>

        <div class="chips">
          <span class="chip">Python</span>
          <span class="chip">SQL</span>
          <span class="chip">PySpark</span>
          <span class="chip">Airflow</span>
          <span class="chip">AWS (S3, Glue, Lambda, Redshift)</span>
          <span class="chip">Snowflake</span>
          <span class="chip">Kafka</span>
          <span class="chip">Hadoop / Hive</span>
          <span class="chip">Databricks</span>
          <span class="chip">Docker</span>
          <span class="chip">Jenkins</span>
          <span class="chip">Terraform</span>
          <span class="chip">Power BI</span>
          <span class="chip">Tableau</span>
        </div>

        <div class="skill-groups">
          <div>
            <h3>Data Engineering</h3>
            <p>ETL/ELT, Data Warehousing, Orchestration, Data Quality, Data Modeling</p>
          </div>
          <div>
            <h3>Databases</h3>
            <p>Snowflake, PostgreSQL, MySQL, MongoDB, Redshift</p>
          </div>
          <div>
            <h3>Cloud</h3>
            <p>AWS, Azure Data Factory</p>
          </div>
        </div>
      </section>

      <section class="card">
        <h2>Featured Projects</h2>
        <p class="muted">Add your GitHub links below (replace the #).</p>

        <div class="project">
          <div class="project-head">
            <h3>YouTube Trending Data Pipeline (AWS)</h3>
            <span class="tag">ETL ‚Ä¢ Analytics</span>
          </div>
          <p>
            End-to-end pipeline using S3 + Glue (PySpark) + Redshift for analytics-ready datasets and SQL insights.
          </p>
          <div class="links">
            <a href="#" target="_blank" rel="noreferrer">GitHub Repo</a>
            <a href="#" target="_blank" rel="noreferrer">Demo / Screenshot</a>
          </div>
        </div>

        <div class="project">
          <div class="project-head">
            <h3>AI Skin Disease Detection + RAG</h3>
            <span class="tag">ML ‚Ä¢ RAG</span>
          </div>
          <p>
            Image classification pipeline with recommendations using retrieval-augmented generation.
          </p>
          <div class="links">
            <a href="#" target="_blank" rel="noreferrer">GitHub Repo</a>
            <a href="#" target="_blank" rel="noreferrer">Demo / Screenshot</a>
          </div>
        </div>
      </section>
    </section>

    <section class="card">
      <h2>Experience</h2>

      <div class="timeline">
        <div class="role">
          <div class="role-head">
            <h3>Data Engineer ‚Äî Fifth Third Bank</h3>
            <p class="muted">Kentwood, MI ‚Ä¢ Oct 2024 ‚Äì Present</p>
          </div>
          <p class="muted">Enterprise Data Platform for Credit Risk & Fraud Analytics</p>
          <ul>
            <li>Built automated ETL pipelines in <b>PySpark</b> + <b>Apache Airflow</b> for ingestion and transformation of transactions and risk data.</li>
            <li>Designed data models in <b>Snowflake</b> to support downstream analytics and BI workloads.</li>
            <li>Implemented an AWS data lake architecture using <b>S3</b>, <b>Glue</b>, and <b>Redshift</b> for scalable storage and querying.</li>
            <li>Created data validation/quality checks to monitor integrity and latency across ingestion layers.</li>
            <li>Optimized SQL queries and Spark jobs, improving pipeline performance by <b>35%</b>.</li>
            <li>Enabled lineage/cataloging with <b>AWS Glue Data Catalog</b> and managed schema evolution.</li>
            <li>Delivered curated data marts for fraud detection dashboards in <b>Power BI</b>.</li>
            <li>Automated monitoring/alerts via <b>CloudWatch</b> and custom logging utilities.</li>
            <li>Supported governance and security requirements (GDPR, Basel III).</li>
          </ul>
          <p class="stack"><b>Stack:</b> Python, PySpark, Airflow, AWS (S3, Glue, Redshift, Lambda), Snowflake, Jenkins, Power BI, SQL</p>
        </div>

        <div class="role">
          <div class="role-head">
            <h3>Data Engineer ‚Äî Cyient</h3>
            <p class="muted">Hyderabad, India ‚Ä¢ Jun 2021 ‚Äì Dec 2023</p>
          </div>
          <p class="muted">Clinical Data Integration and Patient Risk Insights Platform</p>
          <ul>
            <li>Built ingestion and transformation pipelines for EHR/clinical trial/patient data using <b>Airflow</b>, <b>Python</b>, and <b>SQL</b>.</li>
            <li>Developed ETL frameworks for structured/unstructured datasets and automated schema mapping.</li>
            <li>Implemented data quality checks, deduplication, and validation for regulatory compliance (HIPAA).</li>
            <li>Migrated legacy ETL workloads to <b>AWS Glue</b> + <b>PySpark</b>, improving runtime efficiency and reducing ops costs.</li>
            <li>Designed Snowflake warehouse structures to support analytics and reporting.</li>
            <li>Built audit tables and change-data-capture logic to track data flow and lineage.</li>
            <li>Partnered with BI teams to deliver Power BI dashboards for patient analytics.</li>
            <li>Integrated CI/CD with <b>Jenkins</b> for pipeline versioning and deployment.</li>
            <li>Improved processing performance by <b>40%</b> and reduced manual ETL overhead.</li>
          </ul>
          <p class="stack"><b>Stack:</b> Python, SQL, Airflow, AWS Glue, Snowflake, Jenkins, Power BI, Pandas, PySpark</p>
        </div>
      </div>
    </section>

    <section class="grid">
      <section class="card">
        <h2>Education</h2>
        <ul class="clean">
          <li><b>M.S. Computer Science</b> ‚Äî Northern Arizona University (Expected May 2025)</li>
          <li><b>B.Tech Computer Science & Engineering</b> ‚Äî CMR Institute of Technology (Completed 2023)</li>
        </ul>
      </section>

      <section class="card">
        <h2>Certifications</h2>
        <ul class="clean">
          <li>AWS Certified Data Engineer ‚Äì Associate (recommended)</li>
          <li>AWS Certified Machine Learning ‚Äì Specialty</li>
          <li>Microsoft Azure Data Engineer Associate (DP-203)</li>
          <li>Python for Data Science and Data Engineering (Udemy)</li>
          <li>IBM Data Engineering Professional Certificate</li>
        </ul>
      </section>
    </section>

    <section class="card">
      <h2>Resume</h2>
      <p class="muted">
        Add your resume PDF into this repo as <code>resume.pdf</code> and this button will work.
      </p>
      <a class="btn" href="resume.pdf" target="_blank" rel="noreferrer">Download Resume</a>
    </section>
  </main>

  <footer class="container footer">
    <p>¬© <span id="year"></span> Naveen Dharavath ‚Ä¢ Built with GitHub Pages</p>
  </footer>

  <script>
    document.getElementById("year").textContent = new Date().getFullYear();
  </script>
</body>
</html>
